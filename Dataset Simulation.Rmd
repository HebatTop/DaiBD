---
title: "Math stuff for pyspark"
abstract: "A brief summary of our ideas."
keywords: "Statistics, Regression, Forecasting"

course: Statistics (Prof. Dr. Buchwitz)
supervisor: Prof. Dr. Buchwitz
city: Meschede

# List of Authors
author:
- familyname: Giesler
  othernames: Casimir
  address: "MatNr: 123454678"
  qualifications: "Business Administration (BA, 2. Semester)"
  email: curie.marie@fh-swf.de
  correspondingauthor: true


# Language Options
german: false # German Dummy Text
lang: en-gb   # Text Language: en-gb, en-us, de-de

# Indexes
toc: false     # Table of Contents
lot: false    # List of Tables
lof: false    # List of Figures

# Output Options
bibliography: references.bib
biblio-style: authoryear-comp
blind: false
cover: false
checklist: false
output:
  fhswf::seminarpaper:
    fig_caption: yes
    fig_height: 5
    fig_width: 8
    keep_tex: no
    number_sections: yes
    citation_package: biblatex
knit: fhswf::render_seminarpaper
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache=FALSE, messages=FALSE, warning=FALSE, 
                      attr.source='.numberLines', singlespacing = TRUE)
fhswf::fhswf_hooks()

# Load Packages
library(fhswf)
```
\newpage
# Simulation of a Dataset

In order to generate a large dataset which fulfills the requirements ($n \gg 10^9, k\gg 10^5$), the generation of the values needs to be done in a distributed fashion. PySpark does not have a pre-defined function to generate an entire dataset suited for OLS, therefore this function is implemented manually.
At first, the following values need to be initialized:

* `n` - number of rows/samples
* `k` - number of columns/features 
* $\vec{\beta}$ - beta, the coefficients of the function 
* `cov` - a covariance vector that determines the covariance to the first column for each column

In this implementation, `n` and `k` need to be set by the user while $\vec{\beta}$ and `cov` are generated randomly by numpy.
For generating the actual dataset, `pyspark.mllib.random.RandomRDDs.normalVectorRDD(sc, n, k)` is used. This function creates an `rdd` containing `n` vectors, each containing `k` entries, where each entry is generated from a standard-normal distribution.

After generating this random noise matrix, the user-defined-function `createRow(noise)` is applied to the `rdd`, which returns two values, $\vec{x}$ \@ref(eq:gendatax) and $y$ \@ref(eq:gendatay). 

With `noise` as $\epsilon$ and `cov` as $c$:
\begin{equation} 
\vec{x} = (\epsilon_0, \epsilon_0c_1+\epsilon_1, \dots, \epsilon_0c_i+\epsilon_i)
(\#eq:gendatax)
\end{equation}

\begin{equation}
y=\vec{x}\cdot\vec{\beta}
(\#eq:gendatay)
\end{equation}

Applying this function produces an RDD where the first element is the x-vector, and the second element is the target variable.
The resulting feature matrix (consisting out of $n$ $\vec{x}$ vectors) therefore consists out of $k$ columns, where every column is linearly dependent on the first column, plus additional noise.
An exemplary distribution is visualized in figure \@ref(fig:generatedData).

```{r generatedData, echo = FALSE, message=FALSE, fig.align='center', fig.cap='exemplary generated dataset', out.width='1\\linewidth', fig.pos='H'}
knitr::include_graphics("./fig/fig_data_creation.pdf")
```





